{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1257215,"sourceType":"datasetVersion","datasetId":723100}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pip install tensorflow==2.15.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pip install transformers==4.35.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:32:25.882936Z","iopub.execute_input":"2025-01-19T19:32:25.883232Z","iopub.status.idle":"2025-01-19T19:32:28.034086Z","shell.execute_reply.started":"2025-01-19T19:32:25.883199Z","shell.execute_reply":"2025-01-19T19:32:28.033173Z"}},"outputs":[{"name":"stdout","text":"4.35.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  _torch_pytree._register_pytree_node(\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow\nprint(tensorflow.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:32:28.035086Z","iopub.execute_input":"2025-01-19T19:32:28.035404Z","iopub.status.idle":"2025-01-19T19:32:30.676268Z","shell.execute_reply.started":"2025-01-19T19:32:28.035383Z","shell.execute_reply":"2025-01-19T19:32:30.675379Z"}},"outputs":[{"name":"stdout","text":"2.15.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import re\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom transformers import TFDistilBertForSequenceClassification, DistilBertTokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:32:32.709654Z","iopub.execute_input":"2025-01-19T19:32:32.710237Z","iopub.status.idle":"2025-01-19T19:32:33.153317Z","shell.execute_reply.started":"2025-01-19T19:32:32.710206Z","shell.execute_reply":"2025-01-19T19:32:33.152499Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  _torch_pytree._register_pytree_node(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hate-speech-and-offensive-language-dataset/labeled_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:32:54.570060Z","iopub.execute_input":"2025-01-19T19:32:54.570690Z","iopub.status.idle":"2025-01-19T19:32:54.644256Z","shell.execute_reply.started":"2025-01-19T19:32:54.570655Z","shell.execute_reply":"2025-01-19T19:32:54.643634Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:12:49.920746Z","iopub.execute_input":"2025-01-19T20:12:49.921076Z","iopub.status.idle":"2025-01-19T20:12:49.930767Z","shell.execute_reply.started":"2025-01-19T20:12:49.921045Z","shell.execute_reply":"2025-01-19T20:12:49.929889Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"   count  hate_speech  offensive_language  neither  class  \\\n0      3            0                   0        3      2   \n1      3            0                   3        0      1   \n2      3            0                   3        0      1   \n3      3            0                   2        1      1   \n4      6            0                   6        0      1   \n\n                                               tweet  \\\n0  !!! RT @mayasolovely: As a woman you shouldn't...   \n1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n\n                                       cleaned_tweet  label  \n0  rt mayasolovely as a woman you shouldnt compla...      2  \n1  rt mleew17 boy dats coldtyga dwn bad for cuffi...      1  \n2  rt urkindofbrand dawg rt 80sbaby4life you ever...      1  \n3  rt c_g_anderson viva_based she look like a tranny      1  \n4  rt shenikaroberts the shit you hear about me m...      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>hate_speech</th>\n      <th>offensive_language</th>\n      <th>neither</th>\n      <th>class</th>\n      <th>tweet</th>\n      <th>cleaned_tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n      <td>rt mayasolovely as a woman you shouldnt compla...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n      <td>rt mleew17 boy dats coldtyga dwn bad for cuffi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n      <td>rt urkindofbrand dawg rt 80sbaby4life you ever...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n      <td>rt c_g_anderson viva_based she look like a tranny</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n      <td>rt shenikaroberts the shit you hear about me m...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"df['class'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:13:36.454698Z","iopub.execute_input":"2025-01-19T20:13:36.454991Z","iopub.status.idle":"2025-01-19T20:13:36.460766Z","shell.execute_reply.started":"2025-01-19T20:13:36.454966Z","shell.execute_reply":"2025-01-19T20:13:36.459986Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"array([2, 1, 0])"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"df.drop(columns=['Unnamed: 0'],inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:12:45.715964Z","iopub.execute_input":"2025-01-19T20:12:45.716273Z","iopub.status.idle":"2025-01-19T20:12:45.724854Z","shell.execute_reply.started":"2025-01-19T20:12:45.716248Z","shell.execute_reply":"2025-01-19T20:12:45.724013Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:32:54.658998Z","iopub.execute_input":"2025-01-19T19:32:54.659211Z","iopub.status.idle":"2025-01-19T19:32:54.676945Z","shell.execute_reply.started":"2025-01-19T19:32:54.659192Z","shell.execute_reply":"2025-01-19T19:32:54.676073Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 24783 entries, 0 to 24782\nData columns (total 7 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   Unnamed: 0          24783 non-null  int64 \n 1   count               24783 non-null  int64 \n 2   hate_speech         24783 non-null  int64 \n 3   offensive_language  24783 non-null  int64 \n 4   neither             24783 non-null  int64 \n 5   class               24783 non-null  int64 \n 6   tweet               24783 non-null  object\ndtypes: int64(6), object(1)\nmemory usage: 1.3+ MB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def preprocess_text(text):\n    text = re.sub(r\"http\\S+\", \"\", text)\n    text = re.sub(r\"&amp;\", \"&\", text) \n    text = re.sub(r\"[^\\w\\s]\", \"\", text) \n    text = text.strip()  \n    return text.lower()\n\ndf['cleaned_tweet'] = df['tweet'].apply(preprocess_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T19:32:54.678319Z","iopub.execute_input":"2025-01-19T19:32:54.678603Z","iopub.status.idle":"2025-01-19T19:32:54.802232Z","shell.execute_reply.started":"2025-01-19T19:32:54.678580Z","shell.execute_reply":"2025-01-19T19:32:54.801661Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df['label'] = df['class']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:13.460883Z","iopub.execute_input":"2025-01-19T20:14:13.461221Z","iopub.status.idle":"2025-01-19T20:14:13.465354Z","shell.execute_reply.started":"2025-01-19T20:14:13.461190Z","shell.execute_reply":"2025-01-19T20:14:13.464384Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"X = df['cleaned_tweet']\ny = df['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:16.570525Z","iopub.execute_input":"2025-01-19T20:14:16.570821Z","iopub.status.idle":"2025-01-19T20:14:16.581759Z","shell.execute_reply.started":"2025-01-19T20:14:16.570798Z","shell.execute_reply":"2025-01-19T20:14:16.580960Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ndef tokenize_data(texts, labels):\n    encodings = tokenizer(list(texts), truncation=True, padding=True, max_length=128)\n    return encodings, labels\n\ntrain_encodings, train_labels = tokenize_data(X_train, y_train)\nval_encodings, val_labels = tokenize_data(X_val, y_val)\ntest_encodings, test_labels = tokenize_data(X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:22.501353Z","iopub.execute_input":"2025-01-19T20:14:22.501685Z","iopub.status.idle":"2025-01-19T20:14:30.799668Z","shell.execute_reply.started":"2025-01-19T20:14:22.501656Z","shell.execute_reply":"2025-01-19T20:14:30.798715Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def create_tf_dataset(encodings, labels, batch_size=16):\n    dataset = tf.data.Dataset.from_tensor_slices((\n        dict(encodings),\n        labels\n    ))\n\n    dataset = dataset.shuffle(len(labels)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset\n\ntrain_dataset = create_tf_dataset(train_encodings, train_labels)\nval_dataset = create_tf_dataset(val_encodings, val_labels)\ntest_dataset = create_tf_dataset(test_encodings, test_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:30.800774Z","iopub.execute_input":"2025-01-19T20:14:30.801076Z","iopub.status.idle":"2025-01-19T20:14:39.584121Z","shell.execute_reply.started":"2025-01-19T20:14:30.801052Z","shell.execute_reply":"2025-01-19T20:14:39.583418Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:39.585787Z","iopub.execute_input":"2025-01-19T20:14:39.586103Z","iopub.status.idle":"2025-01-19T20:14:40.746876Z","shell.execute_reply.started":"2025-01-19T20:14:39.586079Z","shell.execute_reply":"2025-01-19T20:14:40.745996Z"}},"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"optimizer = Adam(learning_rate=5e-5)\nmodel.compile(\n    optimizer=optimizer,\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:40.765839Z","iopub.execute_input":"2025-01-19T20:14:40.766117Z","iopub.status.idle":"2025-01-19T20:14:40.775680Z","shell.execute_reply.started":"2025-01-19T20:14:40.766081Z","shell.execute_reply":"2025-01-19T20:14:40.774942Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"early_stopping = EarlyStopping(\n    monitor='val_loss',  \n    patience=3,          \n    restore_best_weights=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:40.776540Z","iopub.execute_input":"2025-01-19T20:14:40.776825Z","iopub.status.idle":"2025-01-19T20:14:40.791312Z","shell.execute_reply.started":"2025-01-19T20:14:40.776793Z","shell.execute_reply":"2025-01-19T20:14:40.790609Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"history = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=20, \n    callbacks=[early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:14:40.792116Z","iopub.execute_input":"2025-01-19T20:14:40.792392Z","iopub.status.idle":"2025-01-19T20:27:31.575940Z","shell.execute_reply.started":"2025-01-19T20:14:40.792362Z","shell.execute_reply":"2025-01-19T20:27:31.575192Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n1116/1116 [==============================] - 171s 138ms/step - loss: 0.2981 - accuracy: 0.8949 - val_loss: 0.2615 - val_accuracy: 0.9012\nEpoch 2/20\n1116/1116 [==============================] - 150s 134ms/step - loss: 0.2197 - accuracy: 0.9194 - val_loss: 0.2519 - val_accuracy: 0.9082\nEpoch 3/20\n1116/1116 [==============================] - 150s 134ms/step - loss: 0.1701 - accuracy: 0.9363 - val_loss: 0.2790 - val_accuracy: 0.9153\nEpoch 4/20\n1116/1116 [==============================] - 149s 134ms/step - loss: 0.1227 - accuracy: 0.9542 - val_loss: 0.2901 - val_accuracy: 0.9017\nEpoch 5/20\n1116/1116 [==============================] - 151s 135ms/step - loss: 0.0768 - accuracy: 0.9734 - val_loss: 0.4070 - val_accuracy: 0.9092\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_dataset)\nprint(f\"Test Accuracy: {test_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:27:31.577663Z","iopub.execute_input":"2025-01-19T20:27:31.577891Z","iopub.status.idle":"2025-01-19T20:27:44.340256Z","shell.execute_reply.started":"2025-01-19T20:27:31.577871Z","shell.execute_reply":"2025-01-19T20:27:44.339565Z"}},"outputs":[{"name":"stdout","text":"310/310 [==============================] - 13s 37ms/step - loss: 0.2693 - accuracy: 0.9050\nTest Accuracy: 0.90498286485672\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"example_statements = [\n    \"You should go to hell.\",  # Hate speech\n    \"What an idiot you are!\",  # Offensive language\n    \"Have a nice day!\",  # Neutral/Non-offensive\n]\n\ninputs = tokenizer(example_statements, padding=True, truncation=True, return_tensors=\"tf\")\npredictions = model(inputs).logits\npredicted_classes = tf.argmax(predictions, axis=1)\n\nfor statement, pred_class in zip(example_statements, predicted_classes.numpy()):\n    print(f\"Statement: {statement}\")\n    print(f\"Predicted class: {pred_class}\")\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T20:28:21.360371Z","iopub.execute_input":"2025-01-19T20:28:21.360683Z","iopub.status.idle":"2025-01-19T20:28:21.458234Z","shell.execute_reply.started":"2025-01-19T20:28:21.360658Z","shell.execute_reply":"2025-01-19T20:28:21.457305Z"}},"outputs":[{"name":"stdout","text":"Statement: You should go to hell.\nPredicted class: 1\n\nStatement: What an idiot you are!\nPredicted class: 1\n\nStatement: Have a nice day!\nPredicted class: 2\n\n","output_type":"stream"}],"execution_count":48}]}